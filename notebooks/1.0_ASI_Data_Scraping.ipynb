{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DnD Monsters: Dice and Data\n",
    "As a Dungeon Master, it is very important to understand the strength of the monsters you pit against your players. Too weak, they are bored, too strong, they die or worse..they don't have fun. The current method known as Challenge Rating, CR, is a numerical system used to determine how difficult an enemey is based on a party of 4 players. Challenge Ratings range from 0 to 30. Unfortunately, this method is very basic and often times does not actually hold true to every encounter. \n",
    "\n",
    "One thing that isn't accounted for is action economy. This is the biggest detroyer of players, the strongest weapon in your arsenal. If your players are facing 100 monsters, that's 100 turns. Even if you manage to kill a good chunk of them, the majority will make it through and some of them...with critical hits. Thus is a much more difficult encounter than an equally XP worthwhile monster, with say 2 attacks. \n",
    "\n",
    "Wizards of the Coast not only provide a guideline for how much XP you should have per level per day, but they also show you how much a party of 4 at X level can stomach during one encounter. They also provide an XP multiplier that takes multiple monsters into consideration. For example, 10 monsters get a x2.5 XP multiplier, causing their total XP rating to jump up for the encounter, potentially making them deadly. Action Economy rules all. \n",
    "\n",
    "CR is unfortunately not a great method for measuring a monster's strength. It uses AC, HP, attack bonus, damage per round and Save DC as a general guideline. It doesn't take into account legendary action, at will spells, special abilities that cause status ailments, or any other boosting abilities.\n",
    "\n",
    "There are two CRs: Defensive and Offensive, used to calulate the total CR of a monster. Using the chart provided you find the average of the CR indicated by the HP and AC. Offensive does the same thing but uses DPR and Attack Bonus. Then by averaging the two CRs we get our final monster Challenge Rating. As you can see this doesn't take into account any of the strong abilities a monster may have. Similarly, you may have a weak physical monster that uses spells that is vastly lower in CR than it should be. \n",
    "\n",
    "WoTC has augmented this system by applying multipliers or increases based on other features, trains, or abilities the monster may have. \n",
    "\n",
    "www.dndbeyond.com/monsters has many pages of monster listings. Each listing has a dropdown that has a monster table associated with it. This contains stats, abilities, and other important details. \n",
    "\n",
    "Unfortunately, dndbeyond has shut down its ability to scrape through automation detection software. I don't intend to break to ToS, so I will use the SRD from the dandwiki.com page instead. \n",
    "\n",
    "The goal of this investigation is to learn more about Monster's abilities in relation to the CR system. To understand if there are corellations in any of the stats, abilities, environments, size, etc. To see if we can classify monsters based on any of these traits. To create a dashboard that pits monsters against each other to compare. Finally, to see if there is a way to better address the CR system and use abilities, traits, features, and spells in a more cohesive manner \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnDWiki: html instead of DnDBeyond's javascript\n",
    "DnDBeyond requires javascript parsing, which is more advanced than the knowledge I currently want to practice. I will try\n",
    "to work with DnDWiki instead since it utilizes all html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries for Parsing\n",
    "First we need to gain access to our monster data sheet. as stated above, dndbeyond.com has a great repository of monster data. This will need to be scrapped from there site. Unfortuntately, each of the monster pages is hidden behind an accordion dropdown and will need to be extracted. This is something I have not yet done, so I am excited to try. We will start out using Requests and BeautifulSoup since I am most comfortable with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries for scrapping\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Request for Monster Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching HTML\n",
    "url = \"https://www.dandwiki.com/wiki/5e_SRD:Monsters\"\n",
    "Request = rq.get(url).text\n",
    "\n",
    "soup = bs(Request, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Names of All Monsters in a List \n",
    "Unfortunately, dndwiki is not well crafted, which meant I needed to get creative. There weren't distinguishing classes or names or ids. styles between tables were a bit different, so i used that to gather the information needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the main content div and and extract it for processing\n",
    "#This involves finding the list items that are only housed within the parent table that has a width of 100%.\n",
    "tables = soup.findAll('table',{'style':\"width: 100%;\"})\n",
    "monster_names=[]\n",
    "\n",
    "for table in tables:\n",
    "    li_table = table.findAll('li')\n",
    "    for name in li_table:\n",
    "          monster_names.append(name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up data\n",
    "We need to remove duplicates and non-monsters from the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the non-monster data\n",
    "\n",
    "#Remove Duplicate monsters if there are any\n",
    "monster_names = list(set(monster_names))\n",
    "monster_list=[]\n",
    "#filter through and replace spaces with dashes to format for urls\n",
    "for name in monster_names:\n",
    "    if not(name.strip().isdigit()):\n",
    "        new_name = name.replace(' ','-')\n",
    "        monster_list.append(new_name)\n",
    "    else:\n",
    "        monster_list.append(name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary of URLs to parse\n",
    "We will iterate through the monster name, knowing that dandwiki has a uniform site for all monsters pages www.dandwiki.com/wiki/5e_SRD:'MonsterName'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_url=[]\n",
    "for name in monster_list:\n",
    "    monster_url.append('https://www.dndbeyond.com/monsters/'+name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website Structure is disgusing\n",
    "There are still some things on here that are not monsters (they summon monsters). For example the Deck of Many Things. This will break and analysis or modeling we try to do, so we need to remove them. We can look at all things monsters have in common that these other objects do not. Unfortunately, the DoMT and the figures of power also contain niche \"monster\" stats for their monsters. We will include these in our table, however Zombies and Dinosaurs do not, since they are just a category of many monsters, all of which are included in the list already. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#function to make sure each get request is functioning properly and to parse the url\n",
    "def Run_Soup_If_Status_Ok(url):\n",
    "    request =rq.get(url)\n",
    "    soup = bs(request.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "monster_dict=defaultdict(list)\n",
    "\n",
    "#append dictionary with monster name and the soupy information\n",
    "for name,url in zip(monster_names,monster_url):\n",
    "    monster_dict[name].append(Run_Soup_If_Status_Ok(url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNDBeyond: Testing selenium webdriver on DnDBeyond with a single Monster\n",
    "DnDWiki is frankly just very unhelpful in terms of webstructure. There are no defining class,id,names,or elements on any of the information, which makes parsing a nightmare. I will move into DnDBeyond using Selenium.\n",
    "First we will grab all the information from the Mummy Lord in the 'mon-stat-block' class and the footer information which contains all our tags like source book, environment, and monster tags. We are testing on a single monster\n",
    "to begin writting the scrappings scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingal\\AppData\\Local\\Temp\\ipykernel_2456\\15236720.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path='../env/chromedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.dndbeyond.com/monsters/mummy-lord'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='../env/chromedriver.exe')\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "stat_block = soup.find('div',{'class':'mon-stat-block'})\n",
    "Environment = soup.find('footer')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names: Parsing for headings, labels, and tags\n",
    "Unfortunately, I don't know any one monster that contains every signle type of column we are looking for. The Mummy Lord is a strong enemey that includes a lot of information.\n",
    "I added any column names to the start of the list if they weren't included in the Mummy Lord's stat blocks.\n",
    "\n",
    "Then we create for loops looking for classes that end with label or heading/ start with enviromnnt-tags (later I will decide to expand this to all tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_names = ['Monster Name','Size','Type', 'Alignment','Traits', 'Damage Resistances', 'Monster Tags', 'Mythic Actions', 'Reactions','Source']\n",
    "#First set of column names from 'label span'\n",
    "for headers in stat_block.findAll('span',{'class': lambda e: e.endswith('label') if e else False}):    \n",
    "    column_names.append(headers.text)\n",
    "    \n",
    "for headers in stat_block.findAll('div',{'class': lambda e: e.endswith('heading') if e else False}):    \n",
    "    column_names.append(headers.text)\n",
    "\n",
    "for headers in Environment.findAll('p',{'class': lambda e: e.startswith('environment-tags') if e else False}):    \n",
    "    column_names.append(headers.contents[0].strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Empty Dictionary with Keys from the Extracted Column Names\n",
    "Iterate over the column list, filling a dictionary with a key and empty list value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_dict = dict.fromkeys(column_names)\n",
    "\n",
    "#Initialize the monster_dic with each value for all keys to be an empty list\n",
    "for column in column_names:\n",
    "    monster_dict[column] = []\n",
    "\n",
    "monster_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Values of Mummy Data into our Dictionary\n",
    "Here is our big show stopper. This will be turned into a function to be used in the main scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monster Name\n",
    "monster_name = stat_block.find('div', {'class':'mon-stat-block__name'}).text\n",
    "monster_dict['Monster Name'].append(' '.join(str(monster_name).split())) \n",
    "\n",
    "\n",
    "#This next set (Size,Alignment, and Type) will split the single meta text using split() and replace() functions\n",
    "monster_subinfo = stat_block.find('div', {'class':'mon-stat-block__meta'})\n",
    "monster_subinfo=monster_subinfo.text\n",
    "\n",
    "# Size (first word)\n",
    "monster_size = monster_subinfo.split()[0]\n",
    "monster_dict['Size'].append(monster_size) \n",
    "# Alignment (after comma)\n",
    "monster_alignment = monster_subinfo.split(', ')[-1]\n",
    "monster_dict['Alignment'].append(monster_alignment) \n",
    "# Type (remaining words). The sublist will remove the above two variables from the text, as well as the loose comma.\n",
    "#It will also create a list for the type, as sometimes there are sub-types associated with monsters (e.g Titan)\n",
    "sub_list=(monster_size,monster_alignment, ', ')\n",
    "monster_type = monster_subinfo\n",
    "for substring in sub_list:\n",
    "    monster_type = monster_type.replace(substring,'')\n",
    "monster_type=monster_type.split()\n",
    "monster_dict['Type'].append(monster_type) \n",
    "\n",
    "#find all attribute metrics\n",
    "attribute_data = stat_block.findAll('span',{'class':'mon-stat-block__attribute-data-value'})\n",
    "\n",
    "# Armor Class\n",
    "monster_ac = ' '.join(str(attribute_data[0].text).split())\n",
    "monster_dict['Armor Class'].append(monster_ac)\n",
    "# Hit Points\n",
    "monster_hp = ' '.join(str(attribute_data[1].text).split())\n",
    "monster_dict['Hit Points'].append(monster_hp)\n",
    "# Speed\n",
    "monster_speed = ' '.join(str(attribute_data[2].text).split())\n",
    "monster_dict['Speed'].append(monster_speed)\n",
    "\n",
    "\n",
    "#find all tidbit  metrics\n",
    "tidbit_label = stat_block.findAll('span', {'class':'mon-stat-block__tidbit-label'})\n",
    "\n",
    "for label in tidbit_label:    \n",
    "    '''\n",
    "    Because the tidbits column shifts based on the monster, we can't index the rows, as they\n",
    "    are added or deleted based on the monster. So instead, we will write a for loop that loops through \n",
    "    the monsters tidbit headings (e.g. Skills, Saving Throws, etc.) and if they exits, it will take\n",
    "    the sibling data (i.e. it will take the actual data corresponding to each heading) and deposit it into the dictionary.\n",
    "    Any columns not in the monster data will be left blank for now. Each if statement is labeled with the corresponding tidbit.\n",
    "    '''\n",
    "    if label.text == \"Saving Throws\":\n",
    "        monster_saving_throw = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Saving Throws'].append(monster_saving_throw)\n",
    "    elif label.text == \"Skills\":\n",
    "        monster_skills = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Skills'].append(monster_skills)\n",
    "    elif label.text == \"Damage Vulnerabilities\":    \n",
    "        monster_damage_vulnerability = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Damage Vulnerabilities'].append(monster_damage_vulnerability)\n",
    "    elif label.text == \"Damage Immunities\":\n",
    "        monster_damage_immunity = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Damage Immunities'].append(monster_damage_immunity)\n",
    "    elif label.text == 'Condition Immunities':\n",
    "        monster_condition_immunity = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Condition Immunities'].append(monster_condition_immunity)\n",
    "    elif label.text == 'Senses':\n",
    "        monster_senses = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Senses'].append(monster_senses)\n",
    "    elif label.text == 'Languages':\n",
    "        monster_languages = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Languages'].append(monster_languages)\n",
    "    elif label.text == 'Challenge':\n",
    "        monster_challenge= ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Challenge'].append(monster_challenge)\n",
    "    elif label.text == 'Proficiency Bonus':\n",
    "        monster_proficiency = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Proficiency Bonus'].append(monster_proficiency)\n",
    "    elif label.text == 'Damage Resistances':\n",
    "        monster_damage_resistence = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "        monster_dict['Damage Resistances'].append(monster_damage_resistence)\n",
    "\n",
    "\n",
    "#find all ability score metrics\n",
    "ability_scores = stat_block.findAll('span',{'class':'ability-block__score'})\n",
    "    # STR Score\n",
    "monster_str = ability_scores[0].text\n",
    "monster_dict['STR'].append(monster_str)\n",
    "    # DEX Score\n",
    "monster_dex = ability_scores[1].text\n",
    "monster_dict['DEX'].append(monster_dex)\n",
    "    # CON Score\n",
    "monster_con = ability_scores[2].text\n",
    "monster_dict['CON'].append(monster_con)\n",
    "    # INT Score\n",
    "monster_int = ability_scores[3].text\n",
    "monster_dict['INT'].append(monster_int)\n",
    "    # WIS Score\n",
    "monster_wis = ability_scores[4].text\n",
    "monster_dict['WIS'].append(monster_wis)\n",
    "    # CHA Score\n",
    "monster_cha = ability_scores[5].text\n",
    "monster_dict['CHA'].append(monster_cha)    \n",
    "    \n",
    "# Traits: because traits doesn't contain any defining HTML or any headings such as Actions or Legendary Actions\n",
    "# I searched through all the description blocks of the text. If they don't contain the div 'heading' then we print\n",
    "# This allows us to only print the traits and to place them in a list if need be for later wrangling and analysis. \n",
    "             \n",
    "trait_list = []\n",
    "description_block = stat_block.findAll('div', {'class':'mon-stat-block__description-block'})\n",
    "for block in description_block:\n",
    "     if not block.findAll('div',{'class':'mon-stat-block__description-block-heading'}):\n",
    "        for p in block.findAll('p'):\n",
    "            trait_list.append(p.text)\n",
    "\n",
    "#Remaining descriptions that had headings\n",
    "description_heading = stat_block.findAll('div', {'class':'mon-stat-block__description-block-heading'})\n",
    "action_list=[]\n",
    "for heading in description_heading:    \n",
    "    '''\n",
    "    Because the description column shifts based on the monster, we can't index the rows, as they\n",
    "    are added or deleted based on the monster. So instead, we will write a for loop that loops through \n",
    "    the monsters description headings (e.g. Actions, Legendary Actions, etc.) and if they exits, it will take\n",
    "    the sibling data (i.e. it will take the actual data corresponding to each heading) and deposit it into the dictionary.\n",
    "    Any columns not in the monster data will be left blank for now. Each if statement is labeled with the corresponding tidbit.\n",
    "    '''\n",
    "    action_list=[]\n",
    "    if heading.text == \"Actions\":\n",
    "        monster_actions = heading.find_next_sibling('div')\n",
    "        for p in monster_actions.findAll('p'):\n",
    "           action_list.append(p.text.strip())\n",
    "        monster_dict['Actions'].append(action_list)\n",
    "    elif heading.text == \"Legendary Actions\":\n",
    "        monster_legendary_actions = heading.find_next_sibling('div')\n",
    "        for p in monster_legendary_actions.findAll('p'):\n",
    "           action_list.append(p.text.strip())\n",
    "        monster_dict['Legendary Actions'].append(action_list)\n",
    "    elif heading.text == \"Mythic Actions\":\n",
    "        monster_mythic_actions = heading.find_next_sibling('div')\n",
    "        for p in monster_mythic_actions.findAll('p'):\n",
    "           action_list.append(p.text.strip())\n",
    "        monster_dict['Mythic Actions'].append(action_list)\n",
    "    elif heading.text == \"Reactions\":\n",
    "        monster_reactions = heading.find_next_sibling('div')\n",
    "        for p in monster_reactions.findAll('p'):\n",
    "           action_list.append(p.text.strip())\n",
    "        monster_dict['Reactions'].append(action_list)\n",
    "         \n",
    "#These final traits are either referring to the environment it lives in (can be multiple), the sub type its classified as,\n",
    "# or the source book it came from. all of these or none of these may be represented in the monster sheet.\n",
    "monster_tags = Environment.findAll('span') \n",
    "\n",
    "for tag in Environment.find_all(\"p\"):\n",
    "       \n",
    "    if (tag.contents[0].strip()) == \"Environment:\":\n",
    "       monster_dict['Environment:'].append(monster_tags[0].text)\n",
    "    elif (tag.contents[0].strip()) == \"Monster Tags:\":\n",
    "        monster_dict['Monster Tags'].append(monster_tags[1].text)\n",
    "    else:\n",
    "        monster_dict['Source'].append(tag.contents[0].strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn the dictionary into a dataframe\n",
    "If there are any missing values, replace them with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingal\\AppData\\Local\\Temp\\ipykernel_23144\\1346972013.py:5: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  monster_dict = dict([ (k,pd.Series(v)) for k,v in monster_dict.items()])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monster Name</th>\n",
       "      <th>Size</th>\n",
       "      <th>Type</th>\n",
       "      <th>Alignment</th>\n",
       "      <th>Traits</th>\n",
       "      <th>Damage Resistances</th>\n",
       "      <th>Monster Tags</th>\n",
       "      <th>Mythic Actions</th>\n",
       "      <th>Reactions</th>\n",
       "      <th>Source</th>\n",
       "      <th>...</th>\n",
       "      <th>Proficiency Bonus</th>\n",
       "      <th>STR</th>\n",
       "      <th>DEX</th>\n",
       "      <th>CON</th>\n",
       "      <th>INT</th>\n",
       "      <th>WIS</th>\n",
       "      <th>CHA</th>\n",
       "      <th>Actions</th>\n",
       "      <th>Legendary Actions</th>\n",
       "      <th>Environment:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mummy Lord</td>\n",
       "      <td>Medium</td>\n",
       "      <td>[undead]</td>\n",
       "      <td>lawful evil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Basic Rules</td>\n",
       "      <td>...</td>\n",
       "      <td>+5</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>[Multiattack. The mummy can use its Dreadful G...</td>\n",
       "      <td>[The mummy lord can take 3 legendary actions, ...</td>\n",
       "      <td>Desert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Monster Name    Size      Type    Alignment  Traits  Damage Resistances  \\\n",
       "0   Mummy Lord  Medium  [undead]  lawful evil     NaN                 NaN   \n",
       "\n",
       "   Monster Tags  Mythic Actions  Reactions       Source  ...  \\\n",
       "0           NaN             NaN        NaN  Basic Rules  ...   \n",
       "\n",
       "  Proficiency Bonus STR DEX CON INT WIS CHA  \\\n",
       "0                +5  18  10  17  11  18  16   \n",
       "\n",
       "                                             Actions  \\\n",
       "0  [Multiattack. The mummy can use its Dreadful G...   \n",
       "\n",
       "                                   Legendary Actions Environment:  \n",
       "0  [The mummy lord can take 3 legendary actions, ...       Desert  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensure listlengths are the same\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "monster_dict = dict([ (k,pd.Series(v)) for k,v in monster_dict.items()])\n",
    "monster_dict\n",
    "#list_length = []\n",
    "\n",
    "#for col in monster_dict:\n",
    "#    list_length.append(len(monster_dict[col]))\n",
    "#print(list_length)\n",
    "#\n",
    "monster_df = pd.DataFrame(monster_dict)\n",
    "#\n",
    "monster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_df.to_csv('../data/raw/MummyTest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Over Time to Iterate\n",
    "1. We will change out naming database since DnDBeyond is now active for us. We will need to first iterate through each of the pages of monster files.\n",
    "2. Then we will need to read each monster on each of the page and place them into our monster_list\n",
    "3. Next we will remove any spaces in the monster names and replace them with '-' this will be necessary for the urls\n",
    "4. we will append to the monster url and add to the monster_url list, which we will then use to iterate over for our above test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Request class and Selenium Function\n",
    "We want our final request clean and clear, so we will create a reusable request class with a get_selenium function.\n",
    "This function will randomize our user profile to help protect against throttling/halting the srape. We will \n",
    "also perform this as headless so as not to tax our computer. The function looks for a certain class, and waits a certain\n",
    "amount of time. If it sees the class, the function will return the page_source information, otherwise it will close the \n",
    "browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ser = Service('../env/chromedriver.exe')\n",
    "\n",
    "class Request:\n",
    "\n",
    "        def __init__(self,url):\n",
    "                self.url = url\n",
    "\n",
    "        def get_selenium(self, class_name):\n",
    "                '''\n",
    "                This is the fuction inputs a URL and will output a parse that is headless and also will\n",
    "                randomize the user. \n",
    "                '''\n",
    "                software_names = [SoftwareName.CHROME.value]\n",
    "                operating_systems = [OperatingSystem.WINDOWS.value,\n",
    "                                     OperatingSystem.LINUX.value]\n",
    "                user_agent_rotator = UserAgent(software_names=software_names,\n",
    "                                                operating_systems=operating_systems,\n",
    "                                                limit=100)\n",
    "                user_agent = user_agent_rotator.get_random_user_agent()\n",
    "                chrome_options = Options()\n",
    "                chrome_options.add_argument(\"--headless\")\n",
    "                chrome_options.add_argument('--no-sandbox')\n",
    "                chrome_options.add_argument('--window-size=1420,1080')\n",
    "                chrome_options.add_argument('--disable-gpu')\n",
    "                chrome_options.add_argument(f'user-agent={user_agent}')     \n",
    "                browser = webdriver.Chrome(service=ser,options=chrome_options)\n",
    "                browser.get(self.url)       \n",
    "                time_to_wait = 10   \n",
    "                try:\n",
    "                        WebDriverWait(browser, time_to_wait).until(\n",
    "                                EC.presence_of_element_located((By.CLASS_NAME, class_name))\n",
    "                        )   \n",
    "                except (TimeoutException, WebDriverException):\n",
    "                        browser.quit()\n",
    "                else:\n",
    "                        browser.maximize_window()\n",
    "                        page_html = browser.page_source\n",
    "                        browser.quit()\n",
    "                        return page_html     \n",
    "                            \n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_html = Request('https://www.dndbeyond.com/monsters/adult-green-dragon').get_selenium(\"mon-stat-block__name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DnD Monster Page Iteration\n",
    "The website has the same formula 'https://www.dndbeyond.com/monsters?page=' so we just need to iterate from 1 to 106 (last page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingal\\AppData\\Local\\Temp\\ipykernel_8928\\1833486923.py:37: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(executable_path='../env/chromedriver.exe',chrome_options=chrome_options)\n",
      "C:\\Users\\ingal\\AppData\\Local\\Temp\\ipykernel_8928\\1833486923.py:37: DeprecationWarning: use options instead of chrome_options\n",
      "  browser = webdriver.Chrome(executable_path='../env/chromedriver.exe',chrome_options=chrome_options)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://www.dndbeyond.com/monsters?page='\n",
    "\n",
    "monster__name= []\n",
    "\n",
    "for i in range(1,107):\n",
    "    \n",
    "    page_html = Request(url+i).get_selenium('mon-stat-block__name')\n",
    "    soup = BeautifulSoup(page_html, 'lxml')\n",
    "    page_names = soup.find_all('span',{'class':'name'})\n",
    "\n",
    "    for span in page_names:\n",
    "        monster__name.append(span.text.strip())\n",
    "        \n",
    "    sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_nospace=[]\n",
    "\n",
    "#filter through and replace spaces with dashes to format for urls\n",
    "\n",
    "for name in monster__name:\n",
    "    if not(name.strip().isdigit()):\n",
    "        new_name = name.replace(' ','-')\n",
    "        monster_nospace.append(new_name)\n",
    "    else:\n",
    "        monster_nospace.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_name_preurl = []\n",
    "#filter and replace '()' with nothing\n",
    "for name in monster_nospace:\n",
    "    if not(name.strip().isdigit()):\n",
    "        new_name = name.replace('(','')\n",
    "        final_name = new_name.replace(')','')\n",
    "        monster_name_preurl.append(final_name)\n",
    "    else:\n",
    "        monster_name_preurl.append(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to pull all data from DndBeyond\n",
    "Using our test function from the Mummy, we will iterate over all the monsters in monster_name_preurl\n",
    "to parse each monster page for their data and slam it into the dictionary!\n",
    "\n",
    "we saved our previous variable using store magic, so we don't need to rerun the monster names or column names each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r monster_dict\n",
    "%store -r monster__name\n",
    "%store -r monster_name_preurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def monster_stat_gathering(soup):\n",
    "\n",
    "    stat_block = soup.find('div',{'class':'mon-stat-block'}) \n",
    "    tags = soup.find('footer')\n",
    "\n",
    "    # Monster Name\n",
    "    monster_name = stat_block.find('div', {'class':'mon-stat-block__name'}).text\n",
    "    monster_dict['Monster Name'].append(' '.join(str(monster_name).split())) \n",
    "    \n",
    "    \n",
    "    #This next set (Size,Alignment, and Type) will split the single meta text using split() and replace() functions\n",
    "    monster_subinfo = stat_block.find('div', {'class':'mon-stat-block__meta'})\n",
    "    monster_subinfo=monster_subinfo.text\n",
    "    \n",
    "    # Size (first word)\n",
    "    monster_size = monster_subinfo.split()[0]\n",
    "    monster_dict['Size'].append(monster_size) \n",
    "    # Alignment (after comma)\n",
    "    monster_alignment = monster_subinfo.split(', ')[-1]\n",
    "    monster_dict['Alignment'].append(monster_alignment) \n",
    "    # Type (remaining words). The sublist will remove the above two variables from the text, as well as the loose comma.\n",
    "    #It will also create a list for the type, as sometimes there are sub-types associated with monsters (e.g Titan)\n",
    "    sub_list=(monster_size,monster_alignment, ', ')\n",
    "    monster_type = monster_subinfo\n",
    "    for substring in sub_list:\n",
    "        monster_type = monster_type.replace(substring,'')\n",
    "    monster_type=monster_type.split()\n",
    "    monster_dict['Type'].append(monster_type) \n",
    "    \n",
    "    \n",
    "    #find all attribute metrics\n",
    "    attribute_data = stat_block.findAll('span',{'class':'mon-stat-block__attribute-data-value'})\n",
    "    \n",
    "    # Armor Class\n",
    "    monster_ac = ' '.join(str(attribute_data[0].text).split())\n",
    "    monster_dict['Armor Class'].append(monster_ac)\n",
    "    # Hit Points\n",
    "    monster_hp = ' '.join(str(attribute_data[1].text).split())\n",
    "    monster_dict['Hit Points'].append(monster_hp)\n",
    "    # Speed\n",
    "    monster_speed = ' '.join(str(attribute_data[2].text).split())\n",
    "    monster_dict['Speed'].append(monster_speed)\n",
    "    \n",
    "    \n",
    "    #find all tidbit  metrics\n",
    "    tidbit_label = stat_block.findAll('span', {'class':'mon-stat-block__tidbit-label'})\n",
    "    tidbit_list = []\n",
    "    for label in tidbit_label:    \n",
    "        '''\n",
    "        Because the tidbits column shifts based on the monster, we can't index the rows, as they\n",
    "        are added or deleted based on the monster. So instead, we will write a for loop that loops through \n",
    "        the monsters tidbit headings (e.g. Skills, Saving Throws, etc.) and if they exits, it will take\n",
    "        the sibling data (i.e. it will take the actual data corresponding to each heading) and deposit it into the dictionary.\n",
    "        Any columns not in the monster data will be left blank for now. Each if statement is labeled with the corresponding tidbit.\n",
    "        '''\n",
    "        tidbit_list.append(label.text)\n",
    "        if label.text == \"Saving Throws\":\n",
    "            monster_saving_throw = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Saving Throws'].append(monster_saving_throw)\n",
    "        elif label.text == \"Skills\":\n",
    "            monster_skills = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Skills'].append(monster_skills)\n",
    "        elif label.text == \"Damage Vulnerabilities\":    \n",
    "            monster_damage_vulnerability = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Damage Vulnerabilities'].append(monster_damage_vulnerability)\n",
    "        elif label.text == \"Damage Immunities\":\n",
    "            monster_damage_immunity = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Damage Immunities'].append(monster_damage_immunity)\n",
    "        elif label.text == 'Condition Immunities':\n",
    "            monster_condition_immunity = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Condition Immunities'].append(monster_condition_immunity)\n",
    "        elif label.text == 'Senses':\n",
    "            monster_senses = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Senses'].append(monster_senses)\n",
    "        elif label.text == 'Languages':\n",
    "            monster_languages = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Languages'].append(monster_languages)\n",
    "        elif label.text == 'Challenge':\n",
    "            monster_challenge= ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Challenge'].append(monster_challenge)\n",
    "        elif label.text == 'Proficiency Bonus':\n",
    "            monster_proficiency = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Proficiency Bonus'].append(monster_proficiency)\n",
    "        elif label.text == 'Damage Resistances':\n",
    "            monster_damage_resistence = ' '.join(str(label.find_next_sibling('span').text).split())\n",
    "            monster_dict['Damage Resistances'].append(monster_damage_resistence)\n",
    "\n",
    "    #start with full list of tidbit, which will be removed for everyone that exists within the monster.\n",
    "    missing_tidbit_list=[\"Saving Throws\", \"Skills\", \"Damage Vulnerabilities\", \"Damage Immunities\", \"Condition Immunities\", \"Senses\", \"Languages\", \"Challenge\", \"Proficiency Bonus\", \"Damage Resistances\"]\n",
    "    \n",
    "    for tidbit in tidbit_list:\n",
    "        missing_tidbit_list.remove(tidbit)\n",
    "\n",
    "    #add NaN value to all missing tidbits for this monster\n",
    "    for tidbit in missing_tidbit_list:\n",
    "        monster_dict[tidbit].append(np.NaN)\n",
    "\n",
    "    \n",
    "    #find all ability score metrics\n",
    "    ability_scores = stat_block.findAll('span',{'class':'ability-block__score'})\n",
    "        # STR Score\n",
    "    monster_str = ability_scores[0].text\n",
    "    monster_dict['STR'].append(monster_str)\n",
    "        # DEX Score\n",
    "    monster_dex = ability_scores[1].text\n",
    "    monster_dict['DEX'].append(monster_dex)\n",
    "        # CON Score\n",
    "    monster_con = ability_scores[2].text\n",
    "    monster_dict['CON'].append(monster_con)\n",
    "        # INT Score\n",
    "    monster_int = ability_scores[3].text\n",
    "    monster_dict['INT'].append(monster_int)\n",
    "        # WIS Score\n",
    "    monster_wis = ability_scores[4].text\n",
    "    monster_dict['WIS'].append(monster_wis)\n",
    "        # CHA Score\n",
    "    monster_cha = ability_scores[5].text\n",
    "    monster_dict['CHA'].append(monster_cha)    \n",
    "        \n",
    "    # Traits: because traits doesn't contain any defining HTML or any headings such as Actions or Legendary Actions\n",
    "    # I searched through all the description blocks of the text. If they don't contain the div 'heading' then we print\n",
    "    # This allows us to only print the traits and to place them in a list if need be for later wrangling and analysis. \n",
    "                 \n",
    "    trait_list = []\n",
    "    description_block = stat_block.findAll('div', {'class':'mon-stat-block__description-block'})\n",
    "    for block in description_block:\n",
    "         if not block.findAll('div',{'class':'mon-stat-block__description-block-heading'}):\n",
    "            for p in block.findAll('p'):\n",
    "                trait_list.append(p.text)\n",
    "    \n",
    "    #Remaining descriptions that had headings\n",
    "    description_heading = stat_block.findAll('div', {'class':'mon-stat-block__description-block-heading'})\n",
    "    action_list=[]\n",
    "    for heading in description_heading:    \n",
    "        '''\n",
    "        Because the description column shifts based on the monster, we can't index the rows, as they\n",
    "        are added or deleted based on the monster. So instead, we will write a for loop that loops through \n",
    "        the monsters description headings (e.g. Actions, Legendary Actions, etc.) and if they exits, it will take\n",
    "        the sibling data (i.e. it will take the actual data corresponding to each heading) and deposit it into the dictionary.\n",
    "        Any columns not in the monster data will be left blank for now. Each if statement is labeled with the corresponding tidbit.\n",
    "        '''\n",
    "        action_list=[]\n",
    "        if heading.text == \"Actions\":\n",
    "            monster_actions = heading.find_next_sibling('div')\n",
    "            for p in monster_actions.findAll('p'):\n",
    "               action_list.append(p.text.strip())\n",
    "            monster_dict['Actions'].append(action_list)\n",
    "        elif heading.text == \"Legendary Actions\":\n",
    "            monster_legendary_actions = heading.find_next_sibling('div')\n",
    "            for p in monster_legendary_actions.findAll('p'):\n",
    "               action_list.append(p.text.strip())\n",
    "            monster_dict['Legendary Actions'].append(action_list)\n",
    "        elif heading.text == \"Mythic Actions\":\n",
    "            monster_mythic_actions = heading.find_next_sibling('div')\n",
    "            for p in monster_mythic_actions.findAll('p'):\n",
    "               action_list.append(p.text.strip())\n",
    "            monster_dict['Mythic Actions'].append(action_list)\n",
    "        elif heading.text == \"Reactions\":\n",
    "            monster_reactions = heading.find_next_sibling('div')\n",
    "            for p in monster_reactions.findAll('p'):\n",
    "               action_list.append(p.text.strip())\n",
    "            monster_dict['Reactions'].append(action_list)\n",
    "             \n",
    "    #These final traits are either referring to the environment it lives in (can be multiple), the sub type its classified as,\n",
    "    # or the source book it came from. all of these or none of these may be represented in the monster sheet.\n",
    "    monster_tags = tags.findAll('span') \n",
    "    \n",
    "    for tag in tags.find_all(\"p\"):\n",
    "           \n",
    "        if (tag.contents[0].strip()) == \"Environment:\":\n",
    "           monster_dict['Environment:'].append(monster_tags[0].text)\n",
    "        elif (tag.contents[0].strip()) == \"Monster Tags:\":\n",
    "            monster_dict['Monster Tags'].append(monster_tags[1].text)\n",
    "        else:\n",
    "            monster_dict['Source'].append(tag.contents[0].strip())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del monster_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log in to retrieve our paid content\n",
    "Some of the data is behind a login paywall. We only want to grab the data we have paid for,\n",
    "so we will have selenium log in for us prior to parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingal\\AppData\\Local\\Temp\\ipykernel_11188\\1667537381.py:16: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(executable_path='../env/chromedriver.exe',options=chrome_options)\n"
     ]
    }
   ],
   "source": [
    "url =\"https://www.dndbeyond.com/login\"\n",
    "\n",
    "software_names = [SoftwareName.CHROME.value]\n",
    "operating_systems = [OperatingSystem.WINDOWS.value,\n",
    "                     OperatingSystem.LINUX.value]\n",
    "user_agent_rotator = UserAgent(software_names=software_names,\n",
    "                                operating_systems=operating_systems,\n",
    "                                limit=100)\n",
    "user_agent = user_agent_rotator.get_random_user_agent()\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")\n",
    "#chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--window-size=1420,1080')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')     \n",
    "browser = webdriver.Chrome(executable_path='../env/chromedriver.exe',options=chrome_options)\n",
    "browser.get(url) \n",
    "browser.implicitly_wait(120)\n",
    "\n",
    "browser.find_element(By.ID, \"signin-with-twitch\").click()\n",
    "browser.implicitly_wait(120)\n",
    "\n",
    "browser.find_element(By.ID, \"login-username\").send_keys(\"***REMOVED***\")\n",
    "browser.implicitly_wait(120)\n",
    "\n",
    "browser.find_element(By.ID, \"password-input\").send_keys(\"***REMOVED***\")\n",
    "browser.implicitly_wait(120)\n",
    "\n",
    "browser.find_element(By.XPATH, '//*[@id=\"root\"]/div/div[1]/div[3]/div/div/div/div[3]/form/div/div[3]/button').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over monster pages\n",
    "Don't grab any info that we don't have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "url = 'https://www.dndbeyond.com/monsters/'\n",
    "j=0\n",
    "\n",
    "#iterate through monster names and add to url \n",
    "for i in monster_name_preurl[0:10]:\n",
    "  page_html = None\n",
    "#request the html using selenium function\n",
    "  page_html = Request(url+i).get_selenium('mon-stat-block__name')\n",
    "  j+=1\n",
    "  print(j)\n",
    "#if we get a monster page, the html will not be set to none(it looks for a certain element ID)\n",
    "# use beautifulsoup and our own monster extraction function to place information into dictionary       \n",
    "  if page_html is not None:\n",
    "      soup = BeautifulSoup(page_html, 'lxml')\n",
    "      monster_stat_gathering(soup)\n",
    "      for k,v in monster_dict.items(): #replace blank values with NaN to keep data lined up.\n",
    "        if v == []:\n",
    "          monster_dict[k].append(np.NaN)\n",
    "  sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.dndbeyond.com/monsters/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m page_html \u001b[38;5;241m=\u001b[39m Request(url\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdult-Red-Dragon\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_selenium(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmon-stat-block__name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_html\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m monster_stat_gathering(soup)\n",
      "File \u001b[1;32mc:\\Users\\ingal\\Documents\\Data Science Work\\DnD_Monsters\\env\\lib\\site-packages\\bs4\\__init__.py:312\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):        \u001b[38;5;66;03m# It's a file-type object.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     markup \u001b[38;5;241m=\u001b[39m markup\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    313\u001b[0m         (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[0;32m    315\u001b[0m ):\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# Print out warnings for a couple beginner problems\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# involving passing non-markup to Beautiful Soup.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# just in case that's what the user really wants.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msupports_unicode_filenames):\n\u001b[0;32m    322\u001b[0m         possible_filename \u001b[38;5;241m=\u001b[39m markup\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "url = 'https://www.dndbeyond.com/monsters/'\n",
    "page_html = Request(url+'Adult-Red-Dragon').get_selenium('mon-stat-block__name')\n",
    "soup = BeautifulSoup(page_html, 'lxml')\n",
    "monster_stat_gathering(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U22'), dtype('<U17')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmonster_stat_gathering\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m monster_dict\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mmonster_stat_gathering\u001b[1;34m(soup)\u001b[0m\n\u001b[0;32m     91\u001b[0m all_tidbit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(full_tidbit_list)\n\u001b[0;32m     92\u001b[0m current_tidbit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tidbit_list)\n\u001b[1;32m---> 93\u001b[0m missing_tidbit_list \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_tidbit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_tidbit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tidbit \u001b[38;5;129;01min\u001b[39;00m missing_tidbit_list:\n\u001b[0;32m     97\u001b[0m     monster_dict[tidbit]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mNaN)\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U22'), dtype('<U17')) -> None"
     ]
    }
   ],
   "source": [
    "\n",
    "monster_stat_gathering(soup)\n",
    "\n",
    "monster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#ensure listlengths are the same\n",
    "list_length = []\n",
    "\n",
    "for col in monster_dict:\n",
    "    list_length.append(len(monster_dict[col]))\n",
    "print(list_length)\n",
    "\n",
    "monster_df = pd.DataFrame(monster_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monster Name</th>\n",
       "      <th>Size</th>\n",
       "      <th>Type</th>\n",
       "      <th>Alignment</th>\n",
       "      <th>Traits</th>\n",
       "      <th>Damage Resistances</th>\n",
       "      <th>Monster Tags</th>\n",
       "      <th>Mythic Actions</th>\n",
       "      <th>Reactions</th>\n",
       "      <th>Source</th>\n",
       "      <th>...</th>\n",
       "      <th>Proficiency Bonus</th>\n",
       "      <th>STR</th>\n",
       "      <th>DEX</th>\n",
       "      <th>CON</th>\n",
       "      <th>INT</th>\n",
       "      <th>WIS</th>\n",
       "      <th>CHA</th>\n",
       "      <th>Actions</th>\n",
       "      <th>Legendary Actions</th>\n",
       "      <th>Environment:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult Green Dragon</td>\n",
       "      <td>Huge</td>\n",
       "      <td>[dragon]</td>\n",
       "      <td>lawful evil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Basic Rules</td>\n",
       "      <td>...</td>\n",
       "      <td>+5</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>[Multiattack. The dragon can use its Frightful...</td>\n",
       "      <td>[The dragon can take 3 legendary actions, choo...</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Monster Name  Size      Type    Alignment  Traits  \\\n",
       "0  Adult Green Dragon  Huge  [dragon]  lawful evil     NaN   \n",
       "\n",
       "   Damage Resistances  Monster Tags  Mythic Actions  Reactions       Source  \\\n",
       "0                 NaN           NaN             NaN        NaN  Basic Rules   \n",
       "\n",
       "   ... Proficiency Bonus STR DEX CON INT  WIS CHA  \\\n",
       "0  ...                +5  23  12  21  18   15  17   \n",
       "\n",
       "                                             Actions  \\\n",
       "0  [Multiattack. The dragon can use its Frightful...   \n",
       "\n",
       "                                   Legendary Actions Environment:  \n",
       "0  [The dragon can take 3 legendary actions, choo...       Forest  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monster_df.to_csv('../data/raw/FullTest.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11158ff4dfc0495d90dc4f70a524a558f72f950c55e1eff98a0bc63a2c3afe62"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
